# === IMPORTS Y CARGA DE DATOS ===
import pandas as pd
import numpy as np
import joblib
from math import radians, sin, cos, sqrt, atan2, degrees
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.neural_network import MLPClassifier
from google.colab import files as gfiles

# === SUBIR CSV ===
from google.colab import files

print("üîÉ Sube aqu√≠ tu archivo gps_valid.csv (datos √≠ntegros sin spoofing)")
uploaded = files.upload()  # Selecciona gps_valid.csv

# Nombre del CSV subido
CSV_FILE = "gps_valid.csv"

# Cargar y parsear
df = pd.read_csv(CSV_FILE, parse_dates=["UTC"])
# Separar Lat/Lon
df[["Lat","Lon"]] = df["Position"].str.split(",", expand=True).astype(float)
df = df.sort_values("UTC").reset_index(drop=True)

print(f"‚úÖ Datos cargados: {len(df)} filas")
# === C√ÅLCULO DE FEATURES DE CONTINUIDAD ===
def haversine(lat1, lon1, lat2, lon2):
    R = 6371000  # radio terrestre en metros
    œÜ1, œÜ2 = radians(lat1), radians(lat2)
    ŒîœÜ = radians(lat2 - lat1)
    ŒîŒª = radians(lon2 - lon1)
    a = sin(ŒîœÜ/2)**2 + cos(œÜ1)*cos(œÜ2)*sin(ŒîŒª/2)**2
    d = 2 * R * atan2(sqrt(a), sqrt(1-a))
    y = sin(ŒîŒª) * cos(œÜ2)
    x = cos(œÜ1)*sin(œÜ2) - sin(œÜ1)*cos(œÜ2)*cos(ŒîŒª)
    Œ∏ = (degrees(atan2(y, x)) + 360) % 360
    return d, Œ∏

def compute_continuity_features(df):
    dists, bears = [], []
    for i in range(1, len(df)):
        d, b = haversine(
            df.loc[i-1,"Lat"], df.loc[i-1,"Lon"],
            df.loc[i  ,"Lat"], df.loc[i  ,"Lon"]
        )
        dists.append(d)
        bears.append(b)
    return pd.DataFrame({
        "dist":    np.array(dists, dtype=np.float32),
        "bearing": np.array(bears, dtype=np.float32)
    })

cont_df = compute_continuity_features(df)
y_clean = np.ones(len(cont_df), dtype=int)

print(f"‚úÖ {len(cont_df)} muestras de continuidad calculadas")

# === GENERACI√ìN DE ANOMAL√çAS SINT√âTICAS ===
SEED = 42
ANOMALY_RATIO = 0.2

np.random.seed(SEED)
n = len(cont_df)
n_anom = int(n * ANOMALY_RATIO)
# Seleccion de indices del dataset original
idx = np.random.choice(n, n_anom, replace=False)

# Creacion de un arreglo con valores de spoofing generados
cont_anom_features = []
for j in idx:
    # Toma de datos del dataset original
    d_orig, b_orig = cont_df.loc[j, "dist"], cont_df.loc[j, "bearing"]
    lat0, lon0 = df.loc[j, "Lat"], df.loc[j, "Lon"] # Uso de la funcion Haversine para carcualar valores de latitud y longitud

    # Generacion de parametros aleatorios fuera de ruta entre 5 y 50 kilometros (teniendo en cuenta que el radio esta en kilometros)
    jump_d = np.random.uniform(5_000, 50_000)
    jump_b = np.random.uniform(0, 360)

    # El calculo asume que se tiene un salto a una nueva posicion, simulando un spoofing
    # La anomalia estaria en el punto generado (df.loc[j])
    œÜ = radians(lat0)
    ŒîœÜ = (jump_d * cos(radians(jump_b))) / 6371000
    ŒîŒª = (jump_d * sin(radians(jump_b))) / (6371000 * cos(œÜ))
    lat1 = lat0 + degrees(ŒîœÜ)
    lon1 = lon0 + degrees(ŒîŒª)

    '''
    Calcular las caracter√≠sticas con la funcion  Haversine para el punto an√≥malo en relaci√≥n con el punto anterior, asumiendo que el punto anterior es el que est√° en el √≠ndice j-1 en el DataFrame original (df).
    Se usara la interpretaci√≥n de que el salto modifica la ubicaci√≥n del punto j y que la anomal√≠a se detecta en la caracter√≠stica de continuidad entre j-1 y el j modificado.
    Esto significa que el c√°lculo con la funcion Haversine debe realizarse entre `df.loc[j-1]` y la nueva ubicaci√≥n `(lat1, lon1)`.
    Las caracter√≠sticas `dist` y `bearing` en el √≠ndice `i` dentro de `cont_df` corresponden a la continuidad entre `df.loc[i-1]` y `df.loc[i]`.
    Si queremos introducir una anomal√≠a en el √≠ndice `j` de `cont_df`, deber√≠amos modificar las caracter√≠sticas de continuidad entre `df.loc[j-1]` y una nueva ubicaci√≥n para `df.loc[j]`.

    Las caracter√≠sticas an√≥malas deber√≠an calcularse entre `df.loc[j]` y una nueva ubicaci√≥n para `df.loc[j+1]`.
    El c√≥digo original usaba `df.loc[j]` como punto de inicio del salto y aplicaba el salto para obtener un nuevo punto (lat1, lon1).
    Luego calculaba Haversine entre `df.loc[j]` y este nuevo punto. Este c√°lculo no reemplaza directamente el valor original en `cont_df[j]` (que es entre `df[j]` y `df[j+1]`).

    Supongamos entonces que el objetivo es crear puntos de spoofing. Un paso an√≥malo en el √≠ndice `j` de `cont_df` significa que la transici√≥n desde `df.loc[j]` hacia `df.loc[j+1]` es an√≥mala.
    Deber√≠amos tomar `df.loc[j]` como punto de partida y aplicar un salto para encontrar una nueva ubicaci√≥n para el siguiente punto (que ser√≠a el punto an√≥malo `df.loc[j+1]`).
    '''

    lat_start, lon_start = df.loc[j, "Lat"], df.loc[j, "Lon"]

    œÜ_start = radians(lat_start)
    ŒîœÜ = (jump_d * cos(radians(jump_b))) / 6371000
    ŒîŒª = (jump_d * sin(radians(jump_b))) / (6371000 * cos(œÜ_start))
    lat_anom_next = lat_start + degrees(ŒîœÜ)
    lon_anom_next = lon_start + degrees(ŒîŒª)

    # Calcular las caracter√≠sticas de Haversine para este paso an√≥malo (entre df.loc[j] y la nueva ubicaci√≥n para df.loc[j+1])
    d_anom, b_anom = haversine(lat_start, lon_start, lat_anom_next, lon_anom_next)
    cont_anom_features.append([d_anom, b_anom])

# Se convierte el listado de anomalias en un numpy array
cont_anom_features = np.array(cont_anom_features, dtype=np.float32)

y_anom = np.zeros(n_anom, dtype=int)

# Se combinan los datos del dataset entre integros 1 y anomalos o spoofing 0
X = np.vstack([cont_df.values, cont_anom_features])
y = np.concatenate([y_clean, y_anom])

print(f"‚úÖ Dataset combinado: {X.shape[0]} muestras ({len(y_clean)} √≠ntegros + {n_anom} an√≥malos)")
